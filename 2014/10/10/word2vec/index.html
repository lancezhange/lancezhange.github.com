<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>word2vec | Lancezhange</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta name="generator" content="Hexo 4.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">word2vec</h1><a id="logo" href="/.">Lancezhange</a><p class="description">蓝色战歌</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="http://www.lancezhange.com/grocery-store-of-lancezhange/" target="_blank" rel="noopener"><i class="fa fa-archive"> 笔记</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a><a href="/gallery/"><i class="fa fa-user"> photos</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-4-4"><div class="content_container"><div class="post"><h1 class="post-title">word2vec</h1><div class="post-content"><p>其实听闻<a href="http://code.google.com/p/word2vec/" target="_blank" rel="external">word2vec</a>的鼎鼎大名已经很久了，但 google 的 C 源代码在 windows 下即使用 cygwin 也还是不能 make 成功，总是报出找不到 pthread.h 的错误，而 pthread.h 貌似是 linux 特有的头文件，只好作罢。看到<a href="http://blog.csdn.net/zhoubl668/article/details/24314769" target="_blank" rel="external">别人</a>玩 word2vec 玩的很 high, 真是羡慕<a id="more"></a>。</p>
<p>前些日子，<a href="https://spark.apache.org/" target="_blank" rel="external">spark</a> 发布了 1.1.0 版本，其中首次加入了 word2vec 的实现，于是赶紧拿来尝试了一番。让人失望的是，<a href="http://people.apache.org/~pwendell/spark-1.1.0-snapshot2-docs/mllib-feature-extraction.html" target="_blank" rel="external">官方给出的示例</a>在我的机子上居然没有跑成功，经过一番实验(<code>val line = Source.fromFile(&quot;e:/tempfile/text8&quot;).getLines</code> 返回 <code>java.lang.OutOfMemoryError: Java heap space</code> 的错误，而 <code>val n = sc.textFile(&quot;e:/tempfile/text8&quot;).count</code> 能让 spark 奔溃)，基本可以证实是由于给出的训练文件 text8 格式不对，貌似这个 90M+的文件只有一行，而作为一行，它显然太长了。</p>
<p>不必纠结于此，我们改用英国作家简奥斯汀的名作艾玛(<strong>Emma</strong>)一书（可在 <a href="http://www.gutenberg.org/" target="_blank" rel="external">Project Gutenberg</a>上下载）来做</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">import org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.mllib</span><span class="selector-class">.feature</span><span class="selector-class">.Word2Vec</span></div><div class="line">val <span class="selector-tag">input</span> = sc.textFile(<span class="string">"e:/database/emma/emma.txt"</span>).map(line =&gt; line.split(<span class="string">" "</span>).toSeq)</div><div class="line">val word2vec = new Word2Vec()</div><div class="line">val model = word2vec.fit(input)</div></pre></td></tr></table></figure>
<p>这样，模型顺利训练出来。下面找一下 Emma 的相近词</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> synonyms = model.findSynonyms(<span class="string">"Emma"</span>, <span class="number">40</span>)</div><div class="line"><span class="keyword">for</span>((synonym, cosineSimilarity) &lt;- synonyms) &#123;</div><div class="line">    println(s<span class="string">"<span class="variable">$synonym</span> <span class="variable">$cosineSimilarity</span>"</span>)</div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<p>不过上面这种打印太难看了，改进一下</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">synonyms.foreach&#123;<span class="keyword">case</span> <span class="function">(<span class="params">synonym, cosineSimilarity</span>) =&gt;</span> printf(<span class="string">"%-20s %-20.16f\n"</span>,synonym, cosineSimilarity)&#125;</div></pre></td></tr></table></figure>
<p>效果如下图</p>
<p><img src="http://pic.yupoo.com/lancezhange_v/E7wetj2D/NRDtx.jpg" alt=""></p>
<p>下面考虑用中文文本训练一个模型。我用的训练集是很久以前在<a href="http://datatang.com/" target="_blank" rel="external">数据堂</a>下载的 历届矛盾文学奖 文本集，其中收录的是前 8 届茅盾文学奖获奖作品的文本。在用 spark 做 word2vec 之前，必须先做分词。这里我选择用 R 的 <strong>Rwordseg</strong> 包来做分词，并将结果写入 words.txt 文件中（当然，这里我们做的非常粗糙，就是简单的分词，停用词都没处理；如果有个好点的词典，分词的效果会更好，这是题外话）</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">library(Rwordseg)</div><div class="line"></div><div class="line"><span class="attr">data_dir</span> = <span class="string">"E:/database/历届矛盾文学奖作品/历届茅盾文学奖"</span></div><div class="line"><span class="attr">files</span> = list.files(data_dir,<span class="attr">pattern="*.txt")</span></div><div class="line"><span class="attr">result_file</span> = <span class="string">"e:/tempfile/words.txt"</span></div><div class="line"></div><div class="line">for(i <span class="keyword">in</span> <span class="number">1</span>: length(files))&#123;</div><div class="line">  <span class="attr">filename</span> = paste(data_dir, files[i],<span class="attr">sep="/")</span></div><div class="line">  <span class="attr">content</span> = readLines(filename) <span class="comment"># 每一行是一个字符串</span></div><div class="line">  <span class="attr">term</span> = unlist(lapply(content, segmentCN))</div><div class="line">  write(term, <span class="attr">file</span> = result_file, <span class="attr">append=T,</span> <span class="attr">ncolumns=10)</span></div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<p>得到的 words.txt 不足 40M，然后用 spark 做 word2vec，代码和前面的类似。<br>虽然模型也能顺利训练出来，但是新的问题又冒出来了：在 powershell 下，打印出来的相似词全都是乱码。后来各种尝试，包括转换编码方式，将结果写入文件，写成应用提交而不是 spark-shell 运行，等等，都不能解决这个问题。简直是当初用 Python 处理中文的噩梦重演啊，哭—-最后仍然未能解决这个问题，囧。</p>
<p>但我的 word2vec 体验之旅怎么能就此结束呢。我又尝试了其他途径，如下<br>Python 的 <a href="http://radimrehurek.com/gensim/models/word2vec.html" target="_blank" rel="external">Gensim</a>包也实现了 word2vec 算法，但用 <code>pip install --upgrade gensim</code> 安装之后， 用 <code>import gensim</code> 加载居然出现 “ImportError: cannot import name utils！”错误，最后未能解决，再次失败！<br>Java 的 <a href="http://deeplearning4j.org/compare-dl4j-torch7-pylearn.html" target="_blank" rel="external">DL4J</a>(Deep learning for Java) 工具也有实现 word2vec，但需要安装 LAPACK，这是在 windows 下的又一个噩梦，果断放弃！<br>大神李舰写了 <strong>tmcn.word2vec</strong> 包，不过，不是发布到 CRAN，而是 R-Forge 上，并且还没有编译好的版本，只能用如下命令从源码编译安装：</p>
<pre><code>install.packages(&quot;tmcn.word2vec&quot;, repos=&quot;http://R-Forge.R-project.org&quot;,type=&quot;source&quot;)
</code></pre><p>出现编译错误，无解。</p>
<p>受挫如此，只会让我更加停不下来。皇天不负有心人，终于幸运地找到了一个作者<a href="https://github.com/zhangyafeikimi/word2vec-win32" target="_blank" rel="external">为 windows 调试的 wrod2vec C 源代码版本</a>，并且托管在 github 上，很方便地下载下来，用 cygwin 执行 make, 虽然还是各种报出 unknown character 的 warnings (who cares warnings?)，但好在顺利编译成功，真感谢这个作者啊<br>下面开始训练模型</p>
<pre><code>./word2vec -train e:/tempfile/words.txt -output vectors.bin -cbow 0 -size 200 -window 5 -negative 0 -hs 1 -sample 1e-3 -threads 12 -binary 1
</code></pre><p>(吐槽：我机子的处理能力不行啊，每线程每秒只能处理 6K 余单词，别人随便都是 4W+）<br>然后用下面的命令就能交互查询所给单词的相似词</p>
<pre><code>./distance vectors.bin
</code></pre><p>附上几张结果截图</p>
<img src="http://pic.yupoo.com/lancezhange_v/E7vPD3AB/lajKc.png">
<img src="http://pic.yupoo.com/lancezhange_v/E7vPCLLT/PMzmI.png">
<img src="http://pic.yupoo.com/lancezhange_v/E7vPCCG9/BvLGj.png">
<p>结果还不赖。</p>
<h2 id="Todo"><a href="#Todo" class="headerlink" title="Todo"></a>Todo</h2><ul>
<li>深入了解一下 word2vec 背后的原理，重点研读几篇相关论文，以及有道技术分享的 <a href="http://techblog.youdao.com/?p=915" target="_blank" rel="external">Deep Learning 实战之 Word2vec</a></li>
</ul>
</div></div><div id="lv-container" data-id="city" data-uid="MTAyMC80NDE4Ny8yMDcyMA=="><script>(function(d, s) {
   var j, e = d.getElementsByTagName(s)[0];
   if (typeof LivereTower === 'function') { return; }
   j = d.createElement(s);
   j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
   j.async = true;
   e.parentNode.insertBefore(j, e);
})(document, 'script');

</script></div></div></div><div class="pure-u-1 pure-u-md-4-4"><div id="footer">© <a>2020 </a><a href="/." rel="nofollow">Lancezhange.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme maupassant</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?4e845ffcfaae47e3a33dcf7c6a07205c";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>